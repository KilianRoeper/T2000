{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "374844e8-8aef-42c2-a671-8a4ea998069a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Connection to ADLS bus01prod02 container where pilot data is present\n",
    "storage_account = \"adlsweudpbus01prod02\"\n",
    "key=dbutils.secrets.get(scope=\"credentials\", key=\"SP-Password\")\n",
    "id=dbutils.secrets.get(scope=\"credentials\", key=\"clientId\")\n",
    "spark.conf.set(\"fs.azure.account.auth.type.\" + storage_account + \".dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.\" + storage_account + \".dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.\" + storage_account + \".dfs.core.windows.net\", id)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.\" + storage_account + \".dfs.core.windows.net\", key)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.\" + storage_account + \".dfs.core.windows.net\", \"https://login.microsoftonline.com/505cca53-5750-4134-9501-8d52d5df3cd1/oauth2/token\")\n",
    "\n",
    "%run /Workspace/Repos/kroeper@tbdir.net/Utils/Storage_connection\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"/Workspace/Repos/Misc/Utils/\")\n",
    "\n",
    "from storageConnection import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "\n",
    "\n",
    "conn = StorageConnection('adls_ctp', 'sql_rd')\n",
    "\n",
    "path = \"abfss://al-ctp-pilot-contracts@adlsweudpbus01prod02.dfs.core.windows.net/data/\"\n",
    "df = spark.read.format(\"delta\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2527bbb-37cd-4cd6-a534-670bce770a30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "device_ids = [\n",
    "    'ctp-0020008236', 'ctp-0020008009', 'ctp-0020008214', 'ctp-0020006799',\n",
    "    'ctp-0020007916',  'ctp-0020007025', 'ctp-0020006875', 'ctp-0020007843',\n",
    "    'ctp-0020007885', 'ctp-0020007877', 'ctp-0020008119', 'ctp-0440008057'\n",
    "]\n",
    "start_date = '2022-12-01'\n",
    "end_date = '2023-11-30'\n",
    "prec_sig = '243'                            #[NACT = 0, ACTIVE = 1, DESD = 2, SNA = 3]\n",
    "ElHeatPwrReq_Cval_CCU = '4626'             #[-1600, 1612.75] KW/ SNA = 65535\n",
    "HVAC_BrkResist_CompHeat_Stat = '5661'    #0 == Battery was heated/ 1 == Cabin was heated  --> prec done?/ charging done?\n",
    "Status_Plugin_Charging = '239'          #[NACT = 0, ACTIVE = 1, ERR = 2, SNA = 3]\n",
    "#Battery_Temperature = '318'\n",
    "Outside_Temperature = '4378'\n",
    "Inside_Temperature = '219'\n",
    "Standstill_id = '23'\n",
    "BatteryTemperature_24V1 = '6049'\n",
    "#BatteryTemperature_24V2 = '5130'\n",
    "\n",
    "\n",
    "\n",
    "#MomentaryChargePower = '264'        #momentary available Energy that can be input to reach SOC = 100%\n",
    "#MomentaryDischargePower = '265'     #momentary available Energy that can be used --> 264 & 265 both proportional to SOC\n",
    "HV_CHRG_PWR = '275'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8deade93-6f5b-4345-ac1c-15b2ea8823f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.filter((F.col('SignalID') == BatteryTemperature_24V1) | (F.col('SignalID') == BatteryTemperature_24V2) | (F.col('SignalID') == Battery_Temperature)).filter((df['SignalDate'] >= start_date) & (df['SignalDate'] <= end_date)).filter(df['DeviceID'].isin(device_ids)).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a245b72c-dae2-49df-8a06-3a201095ec25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#filter for the neccessary signals and devices in a given time and pivot the signals \n",
    "df = df.filter((F.col('SignalID') == prec_sig) | (F.col('SignalID') == Status_Plugin_Charging) | (F.col('SignalID') == ElHeatPwrReq_Cval_CCU) | (F.col('SignalID') == HVAC_BrkResist_CompHeat_Stat) | (F.col('SignalID') == HV_CHRG_PWR) | (F.col('SignalID') == BatteryTemperature_24V1) | (F.col('SignalID') == Outside_Temperature) | (F.col('SignalID') == Inside_Temperature) | (F.col('SignalID') == Standstill_id)).filter((df['SignalDate'] >= start_date) & (df['SignalDate'] <= end_date)).filter(df['DeviceID'].isin(device_ids)).orderBy('SignalTimestamp').select('DeviceID', 'CustomerName', 'SignalTimestamp','SignalID', 'SignalValue')\n",
    "\n",
    "df = df.groupBy('DeviceID', 'CustomerName', 'SignalTimestamp').pivot('SignalID', [prec_sig, Status_Plugin_Charging, ElHeatPwrReq_Cval_CCU, HVAC_BrkResist_CompHeat_Stat, HV_CHRG_PWR, BatteryTemperature_24V1, Outside_Temperature, Inside_Temperature, Standstill_id]).agg(F.first('SignalValue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981d1342-881d-4d8d-94c5-ef1bbd883c9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76a767b7-d59d-4f7e-b51e-66c6332f7379",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"DeviceID\").orderBy(\"SignalTimestamp\").rowsBetween(-sys.maxsize, 0)\n",
    "\n",
    "#ForwardFill\n",
    "df = df.withColumn(Standstill_id, F.last(Standstill_id, ignorenulls = True).over(window))\n",
    "df = df.withColumn(prec_sig, F.last(prec_sig, ignorenulls = True).over(window)) #preconditioning\n",
    "df = df.withColumn(Status_Plugin_Charging, F.last(Status_Plugin_Charging, ignorenulls = True).over(window)) #plugcharge\n",
    "df = df.withColumn(HVAC_BrkResist_CompHeat_Stat, F.last(HVAC_BrkResist_CompHeat_Stat, ignorenulls = True).over(window)) #heating status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf8f8d7-6175-4c9d-8cc6-7c31712b6beb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creates lag column for preconditioning to increment the ID when current row prec is 1 and the previous row is != 1 or null\n",
    "window2 = Window.partitionBy(\"DeviceID\").orderBy('SignalTimestamp')\n",
    "df = df.withColumn('lag_243', F.lag(prec_sig).over(window2))\n",
    "df = df.withColumn('lag_23', F.lag(Standstill_id).over(window2))\n",
    "\n",
    "#create ID\n",
    "df = df.withColumn('Prec_ID', F.when(((F.col('lag_243') != 1) | (F.col('lag_243') == None)) & (F.col(prec_sig) == 1), F.sum(prec_sig).over(window))) \n",
    "df = df.withColumn('Standstill_ID', F.when(((F.col('lag_23') != 1) | (F.col('lag_23') == None)) & (F.col(Standstill_id) == 1), F.sum(Standstill_id).over(window))) \n",
    "\n",
    "#forwardfill ID\n",
    "df = df.withColumn('Standstill_ID', F.last('Standstill_ID', ignorenulls = True).over(window))\n",
    "df = df.withColumn('Prec_ID', F.last('Prec_ID', ignorenulls = True).over(window)).filter((F.col('243') == 1) & (F.col(Status_Plugin_Charging) == 1))\n",
    "\n",
    "#create lag column for charging power to find out if sign of previous row is unequal current row\n",
    "df = df.withColumn('lag_275', F.lag(HV_CHRG_PWR).over(window2).cast('float'))\n",
    "\n",
    "#verify change of sign\n",
    "df = df.withColumn('SignChanged', F.when((F.col(HV_CHRG_PWR) > 0) & (F.col('lag_275') < 0) | ((F.col(HV_CHRG_PWR) < 0) & (F.col('lag_275') > 0)), 1).otherwise(0))\n",
    "\n",
    "#df = df.filter(~(F.col('4626') == 'null'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb56e72b-ca60-4262-9f10-db1e88e0e672",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6160e5fb-2d37-4425-9506-bfc9a8a0fe25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp\n",
    "#cast HVAC power to use it for calculation\n",
    "df = df.withColumn(ElHeatPwrReq_Cval_CCU, F.col(ElHeatPwrReq_Cval_CCU).cast('float'))\n",
    "\n",
    "#creates month coulmn to find out overall energy consumption in a given month for a particular vehicle\n",
    "df = df.withColumn('month', F.month(F.col('SignalTimestamp')))\n",
    "\n",
    "#find out:\n",
    "# average HVAC enrgy consumption, \n",
    "# number of the sign changes, \n",
    "# if enrgy consumption was done, \n",
    "# month of a rpeconditioning event,\n",
    "# the consumption time,\n",
    "# if preconditioning was done for the cabin or the battery\n",
    "\n",
    "win = Window.partitionBy(\"DeviceID\", \"CustomerName\", \"Standstill_ID\")\n",
    "\n",
    "df = df.withColumn('End Time Standstill', F.max(\"SignalTimestamp\").over(win))\n",
    "df = df.withColumn('Start Time Standstill', F.min(\"SignalTimestamp\").over(win))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4300fe1-6e35-4344-b71b-ebd1f6453f91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e38133-319b-45fa-bb3d-5e30001f1188",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.groupBy('DeviceID', 'CustomerName', 'Standstill_ID', 'Prec_ID').agg(F.avg(ElHeatPwrReq_Cval_CCU).alias('avg_energyConsumption(KW)'), F.min('SignalTimestamp').alias('start time Preconditioning'), F.max('SignalTimestamp').alias('end time Preconditioning'), F.sum('SignChanged').alias('EnergyConsumed_byBool'), F.avg(HV_CHRG_PWR).alias('EnergyConsumed_byVal'), F.last('month').alias('month'), (unix_timestamp(F.max('SignalTimestamp')) - unix_timestamp(F.min('SignalTimestamp'))).alias('consumption_time Preconditioning'), F.sum(F.when(F.col(HVAC_BrkResist_CompHeat_Stat) == 0, 1).otherwise(0)).alias(\"num_Battery_Consumption\"),  F.sum(F.when(F.col(HVAC_BrkResist_CompHeat_Stat) == 1, 1).otherwise(0)).alias(\"num_Cabin_Consumption\"), F.min('Start Time Standstill').alias('Start Time Standstill'), F.max('End Time Standstill').alias('End Time Standstill'), F.max(BatteryTemperature_24V1).alias('Battery_EndTemperature'), F.min(BatteryTemperature_24V1).alias('Battery_StartTemperature'), F.avg(Outside_Temperature).alias('Avg_OutsideTemperature'), F.min(Inside_Temperature).alias('Start_InsideTemperature'), F.max(Inside_Temperature).alias('End_InsideTemperature'))\n",
    "#df.display()\n",
    "\n",
    "#set energy consumption to zero if it is null -> null means no energy conumption happened in the event of a preconditioning, because no value was send by the signal\n",
    "df = df.withColumn('avg_energyConsumption(KW)', F.when(F.col('avg_energyConsumption(KW)').isNull(), 0).otherwise(F.col('avg_energyConsumption(KW)')))\n",
    "# calculates amount of energy consumed by multiplying consumption time with power\n",
    "df = df.withColumn('Energy_Amount(KWh)', (df['consumption_time Preconditioning'] * df['avg_energyConsumption(KW)'])/60) #divide by 60 to get KW*h from KW*min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670ccd32-9dbd-4532-ab44-2edde2624036",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#sometimes preconditioning happens but no energy is consumed. Usually these events happen when preconditioning lasts for a short time (eg. ID #63 for ctp-0020006875 (Hamburger Hochbahn AG)) \n",
    "\n",
    "#consumption_time in minutes -> used to calculate Energy_Amount (but divided by 60 to get to KWh)\n",
    "\n",
    "#I didn't apply a weighted average because the Signal 4646 is sending data every 30sec +- 2sec\n",
    "\n",
    "#sample data from 2023-04-01 to 2023-08-30\n",
    "\n",
    "#I used signal 239 which is the \"Status Plugin-Charging\" Signal to verify if the charging was done or not  \n",
    "\n",
    "#I extracted the month to be able to calculate the entire energy consumed for each vehicle in a specific month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b2b77a4-227e-40a9-b566-666b27512ebb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef4d21a-a355-46ce-8a4a-51a2a2b13f40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#filters the events in which charging did now happen \n",
    "df = df.filter(~(((F.col('EnergyConsumed_byVal').isNull()) | ((F.col('EnergyConsumed_byVal') < 0) & (F.col('EnergyConsumed_byVal') > -1))) & (F.col('EnergyConsumed_byBool') == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4175eec-14f9-422b-af93-3dca82ec534b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a48a15d-fc55-4236-b6d9-38970f8c8d56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter(F.col('consumption_time Preconditioning') <= 500000)\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ddd6c5-87d2-433a-8a8f-96d5704221c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3220495237065401>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m conn\u001B[38;5;241m.\u001B[39msql_rd\u001B[38;5;241m.\u001B[39mwrite_table(data\u001B[38;5;241m=\u001B[39mdf,table_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrd.CTP_Sales_Preconditioning_Consumption\u001B[39m\u001B[38;5;124m'\u001B[39m,mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m'\u001B[39m,truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
       "\u001B[0;32m----> 2\u001B[0m conn\u001B[38;5;241m.\u001B[39msql_rd\u001B[38;5;241m.\u001B[39mexecute_query()\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: StorageConnection.sql_rd.execute_query() missing 1 required positional argument: 'query'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3220495237065401>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m conn\u001B[38;5;241m.\u001B[39msql_rd\u001B[38;5;241m.\u001B[39mwrite_table(data\u001B[38;5;241m=\u001B[39mdf,table_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrd.CTP_Sales_Preconditioning_Consumption\u001B[39m\u001B[38;5;124m'\u001B[39m,mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m'\u001B[39m,truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 2\u001B[0m conn\u001B[38;5;241m.\u001B[39msql_rd\u001B[38;5;241m.\u001B[39mexecute_query()\n\n\u001B[0;31mTypeError\u001B[0m: StorageConnection.sql_rd.execute_query() missing 1 required positional argument: 'query'",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: StorageConnection.sql_rd.execute_query() missing 1 required positional argument: 'query'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn.sql_rd.write_table(data=df,table_name='rd.CTP_Sales_Preconditioning_Consumption',mode='append',truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EnergyConsumption_duringPreconditioning",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
